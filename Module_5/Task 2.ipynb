{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mlPs3fZN0o-_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1663581078157,
     "user": {
      "displayName": "Marharyta Varatnitskaya",
      "userId": "06643565085318986478"
     },
     "user_tz": -120
    },
    "id": "sqZTNur45HxR",
    "outputId": "7d67941c-b04d-4ba2-b52a-48039af2c26b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#define device\n",
    "device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EP5CJomM_PpV"
   },
   "source": [
    "## Generate data for our future Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RdaQyyGikTeA"
   },
   "outputs": [],
   "source": [
    "# generate randomly sequence from 0 to 9 for x, and y: y_1 = x1, then y_i = x_i + x_1, if y_i >= 10, then y_i = y_i -10\n",
    "torch.manual_seed(69)\n",
    "x = torch.randint(high = 9, size = (1000, ), device = device, dtype = torch.float64).long()\n",
    "y = torch.zeros(x.shape, device = device, dtype = torch.float64).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "m5wNUUi83Lv8"
   },
   "outputs": [],
   "source": [
    "#generate corresponding y\n",
    "for i in range(len(x)):\n",
    "  if i == 0:\n",
    "    y[i] = x[i]\n",
    "  else:\n",
    "    y[i] = x[i] + x[0]\n",
    "    if y[i] >= 10:\n",
    "      y[i] = y[i] - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zSCgRuB2dvqk"
   },
   "outputs": [],
   "source": [
    "# view tensors as sequences of 10\n",
    "x_batch = x.view(-1, 10)\n",
    "y_batch = y.view(-1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TsJWxj1PdlKb"
   },
   "outputs": [],
   "source": [
    "# create pairs x and y\n",
    "len_examples = len(y_batch)\n",
    "dataset = []\n",
    "for i in range(len_examples):\n",
    "  dataset.append([x_batch[i], y_batch[i]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1663581091107,
     "user": {
      "displayName": "Marharyta Varatnitskaya",
      "userId": "06643565085318986478"
     },
     "user_tz": -120
    },
    "id": "Neilhg_zeXpe",
    "outputId": "d1e4ecbd-6928-4a5d-831b-fb292409368e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([3, 5, 8, 8, 5, 5, 5, 4, 0, 8]),\n",
       "  tensor([0, 2, 5, 5, 2, 2, 2, 1, 7, 5])],\n",
       " [tensor([1, 4, 2, 8, 4, 5, 1, 7, 1, 3]),\n",
       "  tensor([8, 1, 9, 5, 1, 2, 8, 4, 8, 0])]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creat test-train split 80 % test\n",
    "train_tensor = dataset[:int(len(y_batch)*0.8)]\n",
    "test_tensor = dataset[int(len(y_batch)*0.8):]\n",
    "test_tensor[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-U21DZ9up56Y"
   },
   "outputs": [],
   "source": [
    "embedding_size = 10\n",
    "hidden_size = 10\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3F5kvrQa_hnk"
   },
   "source": [
    "LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfG6pjBvo_-H"
   },
   "outputs": [],
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "        \n",
    "    def __init__(self, num_classes = num_classes, embedding_dim = embedding_size, hidden_dim = hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = torch.nn.Embedding(num_classes, embedding_dim)\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim) \n",
    "        self.linear = torch.nn.Linear(hidden_dim, num_classes)\n",
    "        # Initialize h0 and c0:\n",
    "        self.hidden = (torch.zeros(1,1,hidden_dim).to(device),\n",
    "                       torch.zeros(1,1,hidden_dim).to(device))\n",
    "\n",
    "    def forward(self, X):\n",
    "        model_in = self.embedding(X)\n",
    "        model_in = model_in.unsqueeze(1)\n",
    "        model_out, self.hidden = self.lstm(model_in, self.hidden)\n",
    "        pred = self.linear(model_out)\n",
    "        pred = pred.transpose(1, 2)\n",
    "        return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1663581203369,
     "user": {
      "displayName": "Marharyta Varatnitskaya",
      "userId": "06643565085318986478"
     },
     "user_tz": -120
    },
    "id": "r3r9PUw6pFCv",
    "outputId": "3ada20a4-aa86-4681-f6bf-2a0807e5e12d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embedding): Embedding(10, 10)\n",
       "  (lstm): LSTM(10, 10)\n",
       "  (linear): Linear(in_features=10, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM()\n",
    "softmax = torch.nn.functional.softmax\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5888,
     "status": "ok",
     "timestamp": 1663581211653,
     "user": {
      "displayName": "Marharyta Varatnitskaya",
      "userId": "06643565085318986478"
     },
     "user_tz": -120
    },
    "id": "QQ_-nFCbfs8X",
    "outputId": "04f39d79-2cfd-440b-ef05-61fcdeb4972b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Loss: 0.2790\n",
      "Epoch: 1\n",
      "Loss: 0.0554\n",
      "Epoch: 2\n",
      "Loss: 0.0266\n",
      "Epoch: 3\n",
      "Loss: 0.0163\n",
      "Epoch: 4\n",
      "Loss: 0.0114\n",
      "Epoch: 5\n",
      "Loss: 0.0086\n",
      "Epoch: 6\n",
      "Loss: 0.0068\n",
      "Epoch: 7\n",
      "Loss: 0.0056\n",
      "Epoch: 8\n",
      "Loss: 0.0047\n",
      "Epoch: 9\n",
      "Loss: 0.0040\n",
      "Epoch: 10\n",
      "Loss: 0.0034\n",
      "Epoch: 11\n",
      "Loss: 0.0030\n",
      "Epoch: 12\n",
      "Loss: 0.0026\n",
      "Epoch: 13\n",
      "Loss: 0.0023\n",
      "Epoch: 14\n",
      "Loss: 0.0020\n",
      "Epoch: 15\n",
      "Loss: 0.0018\n",
      "Epoch: 16\n",
      "Loss: 0.0017\n",
      "Epoch: 17\n",
      "Loss: 0.0015\n",
      "Epoch: 18\n",
      "Loss: 0.0014\n",
      "Epoch: 19\n",
      "Loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "accuracies, max_accuracy = [], 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    for x, y in train_tensor:\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden = (torch.zeros(1,1,model.hidden_dim),\n",
    "                        torch.zeros(1,1,model.hidden_dim))\n",
    "        prediction = model(x)\n",
    "        #print(f'prediction {prediction}')\n",
    "        y = y.unsqueeze(1)\n",
    "        #print(f'y {y}')\n",
    "        # Calculate loss.\n",
    "        loss = criterion(prediction, y) \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "    print('Loss: {:6.4f}'.format(loss.item()))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1663580178141,
     "user": {
      "displayName": "Marharyta Varatnitskaya",
      "userId": "06643565085318986478"
     },
     "user_tz": -120
    },
    "id": "aqEXtxdctfIp",
    "outputId": "82fdb382-9bac-4de1-d10d-9713eea6bd6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 2, 4, 4, 7, 5, 9, 0, 8, 3]) tensor([3, 2, 4, 4, 7, 5, 9, 0, 8, 3])\n",
      "tensor([8, 8, 6, 6, 2, 0, 2, 3, 4, 2]) tensor([8, 8, 6, 6, 2, 0, 2, 3, 4, 2])\n",
      "tensor([4, 9, 6, 8, 4, 9, 2, 7, 9, 8]) tensor([4, 9, 6, 8, 4, 9, 2, 7, 9, 8])\n",
      "tensor([8, 6, 0, 7, 6, 0, 3, 4, 0, 9]) tensor([8, 6, 0, 7, 6, 0, 3, 4, 0, 9])\n",
      "tensor([5, 7, 4, 7, 7, 0, 4, 0, 7, 5]) tensor([5, 7, 4, 7, 7, 0, 4, 0, 7, 5])\n",
      "tensor([5, 4, 2, 2, 0, 8, 7, 3, 6, 6]) tensor([5, 4, 2, 2, 0, 8, 7, 3, 6, 6])\n",
      "tensor([7, 6, 7, 5, 5, 0, 5, 0, 5, 9]) tensor([7, 6, 7, 5, 5, 0, 5, 0, 5, 9])\n",
      "tensor([3, 5, 9, 0, 5, 9, 0, 3, 6, 8]) tensor([3, 5, 9, 0, 5, 9, 0, 3, 6, 8])\n",
      "tensor([8, 3, 9, 6, 9, 8, 0, 8, 3, 0]) tensor([8, 3, 9, 6, 9, 8, 0, 8, 3, 0])\n",
      "tensor([3, 4, 4, 4, 8, 9, 4, 2, 4, 6]) tensor([3, 4, 4, 4, 8, 9, 4, 2, 4, 6])\n",
      "tensor([4, 9, 5, 9, 4, 5, 4, 4, 7, 4]) tensor([4, 9, 5, 9, 4, 5, 4, 4, 7, 4])\n",
      "tensor([7, 5, 9, 3, 3, 5, 3, 5, 0, 8]) tensor([7, 5, 9, 3, 3, 5, 3, 5, 0, 8])\n",
      "tensor([5, 2, 4, 0, 6, 8, 8, 2, 5, 7]) tensor([5, 2, 4, 0, 6, 8, 8, 2, 5, 7])\n",
      "tensor([5, 8, 6, 2, 7, 0, 8, 8, 0, 3]) tensor([5, 8, 6, 2, 7, 0, 8, 8, 0, 3])\n",
      "tensor([2, 7, 2, 9, 8, 9, 0, 9, 6, 0]) tensor([2, 7, 2, 9, 8, 9, 0, 9, 6, 0])\n",
      "tensor([4, 9, 7, 9, 6, 7, 8, 9, 9, 5]) tensor([4, 9, 7, 9, 6, 7, 8, 9, 9, 5])\n",
      "tensor([0, 4, 8, 3, 7, 8, 0, 6, 9, 6]) tensor([0, 4, 8, 3, 7, 8, 0, 6, 9, 6])\n",
      "tensor([7, 6, 4, 2, 0, 8, 0, 3, 8, 9]) tensor([7, 6, 4, 2, 0, 8, 0, 3, 8, 9])\n",
      "tensor([5, 6, 5, 8, 0, 4, 5, 2, 9, 9]) tensor([5, 6, 5, 8, 0, 4, 5, 2, 9, 9])\n",
      "tensor([0, 6, 4, 0, 9, 3, 3, 7, 0, 8]) tensor([0, 6, 4, 0, 9, 3, 3, 7, 0, 8])\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "        matches, total = 0, 0\n",
    "        for x, y in test_tensor:\n",
    "            model.eval()\n",
    "            model.hidden = (torch.zeros(1,1,model.hidden_dim),\n",
    "                        torch.zeros(1,1,model.hidden_dim))\n",
    "            scores = model(x)\n",
    "            # Compute a softmax over the outputs\n",
    "            predictions = softmax(scores, dim=1)\n",
    "            # Choose the number with the maximum probability\n",
    "            _, batch_out = predictions.max(dim=1)\n",
    "            # Remove fake dimension\n",
    "            batch_out = batch_out.squeeze(1)\n",
    "            # Calculate accuracy\n",
    "            matches += torch.eq(batch_out, y).sum().item()\n",
    "            print(batch_out, y)\n",
    "            total += torch.numel(batch_out)\n",
    "        accuracy = matches / total\n",
    "        print('Accuracy: {:4.2f}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Mk28H7q_pPl"
   },
   "source": [
    "Simple RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYPv7p1l1Ukk"
   },
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "        \n",
    "    def __init__(self, num_classes = num_classes, embedding_dim = embedding_size, hidden_dim = hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_classes, embedding_dim)\n",
    "        self.rnn = torch.nn.RNN(embedding_dim, hidden_dim) \n",
    "        self.linear = torch.nn.Linear(hidden_dim, num_classes)\n",
    "        # Initialize hidden:\n",
    "        #self.hidden = torch.zeros(1,1,hidden_dim)\n",
    "\n",
    "    def forward(self, X):\n",
    "        model_in = self.embedding(X)\n",
    "        model_in = model_in.unsqueeze(1)\n",
    "        out, hidden = self.rnn(model_in)\n",
    "        out = self.linear(out)\n",
    "        out = out.view(-1, num_classes).squeeze()\n",
    "        out = out.unsqueeze(2)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1663581256400,
     "user": {
      "displayName": "Marharyta Varatnitskaya",
      "userId": "06643565085318986478"
     },
     "user_tz": -120
    },
    "id": "GxSVYknD38rK",
    "outputId": "6d1c0142-3318-45c8-d057-040d80470250"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(10, 10)\n",
       "  (rnn): RNN(10, 10)\n",
       "  (linear): Linear(in_features=10, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RNN = RNN()\n",
    "softmax = torch.nn.functional.softmax\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_RNN.parameters(), lr=0.01)\n",
    "model_RNN.to(device)\n",
    "model_RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4488,
     "status": "ok",
     "timestamp": 1663580182616,
     "user": {
      "displayName": "Marharyta Varatnitskaya",
      "userId": "06643565085318986478"
     },
     "user_tz": -120
    },
    "id": "vUIB7_3a4Bf8",
    "outputId": "e21a2e02-1d77-4687-8e35-66edcb67a490"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Loss: 0.2277\n",
      "Epoch: 1\n",
      "Loss: 0.0461\n",
      "Epoch: 2\n",
      "Loss: 0.0237\n",
      "Epoch: 3\n",
      "Loss: 0.0153\n",
      "Epoch: 4\n",
      "Loss: 0.0111\n",
      "Epoch: 5\n",
      "Loss: 0.0087\n",
      "Epoch: 6\n",
      "Loss: 0.0071\n",
      "Epoch: 7\n",
      "Loss: 0.0060\n",
      "Epoch: 8\n",
      "Loss: 0.0052\n",
      "Epoch: 9\n",
      "Loss: 0.0046\n",
      "Epoch: 10\n",
      "Loss: 0.0042\n",
      "Epoch: 11\n",
      "Loss: 0.0038\n",
      "Epoch: 12\n",
      "Loss: 0.0035\n",
      "Epoch: 13\n",
      "Loss: 0.0032\n",
      "Epoch: 14\n",
      "Loss: 0.0030\n",
      "Epoch: 15\n",
      "Loss: 0.0028\n",
      "Epoch: 16\n",
      "Loss: 0.0027\n",
      "Epoch: 17\n",
      "Loss: 0.0025\n",
      "Epoch: 18\n",
      "Loss: 0.0024\n",
      "Epoch: 19\n",
      "Loss: 0.0023\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "accuracies, max_accuracy = [], 0\n",
    "for epoch in range(num_epochs):\n",
    "    model_RNN.train()\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    for x, y in train_tensor:\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model_RNN(x)\n",
    "        #print(prediction.shape)\n",
    "        #print(f'prediction {prediction}')\n",
    "        y_in = y.unsqueeze(1)\n",
    "        #print(f'y_in {y_in}')\n",
    "        # Calculate loss\n",
    "        loss = criterion(prediction, y_in) \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Loss: {:6.4f}'.format(loss.item()))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1663580182618,
     "user": {
      "displayName": "Marharyta Varatnitskaya",
      "userId": "06643565085318986478"
     },
     "user_tz": -120
    },
    "id": "Xl9p0N9f4Gd_",
    "outputId": "bb17f635-308f-472f-b3ae-4c02bfc39916"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 2, 4, 4, 7, 5, 9, 0, 8, 3]) tensor([3, 2, 4, 4, 7, 5, 9, 0, 8, 3])\n",
      "tensor([8, 8, 6, 6, 2, 0, 2, 3, 4, 2]) tensor([8, 8, 6, 6, 2, 0, 2, 3, 4, 2])\n",
      "tensor([4, 9, 6, 8, 4, 9, 2, 7, 9, 8]) tensor([4, 9, 6, 8, 4, 9, 2, 7, 9, 8])\n",
      "tensor([8, 6, 0, 7, 6, 0, 3, 4, 0, 9]) tensor([8, 6, 0, 7, 6, 0, 3, 4, 0, 9])\n",
      "tensor([5, 7, 4, 7, 7, 0, 4, 0, 7, 5]) tensor([5, 7, 4, 7, 7, 0, 4, 0, 7, 5])\n",
      "tensor([5, 4, 2, 2, 0, 8, 7, 3, 6, 6]) tensor([5, 4, 2, 2, 0, 8, 7, 3, 6, 6])\n",
      "tensor([7, 6, 7, 5, 5, 0, 5, 0, 5, 9]) tensor([7, 6, 7, 5, 5, 0, 5, 0, 5, 9])\n",
      "tensor([3, 5, 9, 0, 5, 9, 0, 3, 6, 8]) tensor([3, 5, 9, 0, 5, 9, 0, 3, 6, 8])\n",
      "tensor([8, 3, 9, 6, 9, 8, 0, 8, 3, 0]) tensor([8, 3, 9, 6, 9, 8, 0, 8, 3, 0])\n",
      "tensor([3, 4, 4, 4, 8, 9, 4, 2, 4, 6]) tensor([3, 4, 4, 4, 8, 9, 4, 2, 4, 6])\n",
      "tensor([4, 9, 5, 9, 4, 5, 4, 4, 7, 4]) tensor([4, 9, 5, 9, 4, 5, 4, 4, 7, 4])\n",
      "tensor([7, 5, 9, 3, 3, 5, 3, 5, 0, 8]) tensor([7, 5, 9, 3, 3, 5, 3, 5, 0, 8])\n",
      "tensor([5, 2, 4, 0, 6, 8, 8, 2, 5, 7]) tensor([5, 2, 4, 0, 6, 8, 8, 2, 5, 7])\n",
      "tensor([5, 8, 6, 2, 7, 0, 8, 8, 0, 3]) tensor([5, 8, 6, 2, 7, 0, 8, 8, 0, 3])\n",
      "tensor([2, 7, 2, 9, 8, 9, 0, 9, 6, 0]) tensor([2, 7, 2, 9, 8, 9, 0, 9, 6, 0])\n",
      "tensor([4, 9, 7, 9, 6, 7, 8, 9, 9, 5]) tensor([4, 9, 7, 9, 6, 7, 8, 9, 9, 5])\n",
      "tensor([0, 4, 8, 3, 7, 8, 0, 6, 9, 6]) tensor([0, 4, 8, 3, 7, 8, 0, 6, 9, 6])\n",
      "tensor([7, 6, 4, 2, 0, 8, 0, 3, 8, 9]) tensor([7, 6, 4, 2, 0, 8, 0, 3, 8, 9])\n",
      "tensor([5, 6, 5, 8, 0, 4, 5, 2, 9, 9]) tensor([5, 6, 5, 8, 0, 4, 5, 2, 9, 9])\n",
      "tensor([0, 6, 4, 0, 9, 3, 3, 7, 0, 8]) tensor([0, 6, 4, 0, 9, 3, 3, 7, 0, 8])\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "        matches, total = 0, 0\n",
    "        for x, y in test_tensor:\n",
    "            model_RNN.eval()\n",
    "            scores = model_RNN(x)\n",
    "            # Compute a softmax over the outputs\n",
    "            predictions = softmax(scores, dim=1)\n",
    "            # Choose the number with the maximum probability\n",
    "            _, batch_out = predictions.max(dim=1)\n",
    "            # Remove fake dimension\n",
    "            batch_out = batch_out.squeeze(1)\n",
    "            # Calculate accuracy\n",
    "            matches += torch.eq(batch_out, y).sum().item()\n",
    "            print(batch_out, y)\n",
    "            total += torch.numel(batch_out)\n",
    "        accuracy = matches / total\n",
    "        print('Accuracy: {:4.2f}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iY11H0p--_o6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-Xru4w3_44S"
   },
   "source": [
    "GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cqonjl__3iU"
   },
   "outputs": [],
   "source": [
    "class GRU(torch.nn.Module):\n",
    "        \n",
    "    def __init__(self, num_classes = num_classes, embedding_dim = embedding_size, hidden_dim = hidden_size):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = torch.nn.Embedding(num_classes, embedding_dim)\n",
    "        self.gru = torch.nn.GRU(embedding_dim, hidden_dim) \n",
    "        self.linear = torch.nn.Linear(hidden_dim, num_classes)\n",
    "        # Initialize h0:\n",
    "        self.hidden = torch.zeros(1,1,hidden_dim).to(device)\n",
    "\n",
    "    def forward(self, X):\n",
    "        model_in = self.embedding(X)\n",
    "        model_in = model_in.unsqueeze(1)\n",
    "        model_out, self.hidden = self.gru(model_in, self.hidden)\n",
    "        pred = self.linear(model_out)\n",
    "        pred = pred.transpose(1, 2)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1663581284947,
     "user": {
      "displayName": "Marharyta Varatnitskaya",
      "userId": "06643565085318986478"
     },
     "user_tz": -120
    },
    "id": "sXKKWwkp_1e-",
    "outputId": "0e792369-f7f6-44c4-c34c-2ca60c4a1418"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU(\n",
       "  (embedding): Embedding(10, 10)\n",
       "  (gru): GRU(10, 10)\n",
       "  (linear): Linear(in_features=10, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_GRU = GRU()\n",
    "softmax = torch.nn.functional.softmax\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_GRU.parameters(), lr=0.01)\n",
    "model_GRU.to(device)\n",
    "model_GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6102,
     "status": "ok",
     "timestamp": 1663581291669,
     "user": {
      "displayName": "Marharyta Varatnitskaya",
      "userId": "06643565085318986478"
     },
     "user_tz": -120
    },
    "id": "hyH9Xp59FAiy",
    "outputId": "1482c82c-f069-4571-fd74-6e61b50114b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Loss: 0.2250\n",
      "Epoch: 1\n",
      "Loss: 0.0500\n",
      "Epoch: 2\n",
      "Loss: 0.0248\n",
      "Epoch: 3\n",
      "Loss: 0.0155\n",
      "Epoch: 4\n",
      "Loss: 0.0098\n",
      "Epoch: 5\n",
      "Loss: 0.0073\n",
      "Epoch: 6\n",
      "Loss: 0.0057\n",
      "Epoch: 7\n",
      "Loss: 0.0047\n",
      "Epoch: 8\n",
      "Loss: 0.0039\n",
      "Epoch: 9\n",
      "Loss: 0.0033\n",
      "Epoch: 10\n",
      "Loss: 0.0028\n",
      "Epoch: 11\n",
      "Loss: 0.0024\n",
      "Epoch: 12\n",
      "Loss: 0.0021\n",
      "Epoch: 13\n",
      "Loss: 0.0019\n",
      "Epoch: 14\n",
      "Loss: 0.0016\n",
      "Epoch: 15\n",
      "Loss: 0.0014\n",
      "Epoch: 16\n",
      "Loss: 0.0013\n",
      "Epoch: 17\n",
      "Loss: 0.0012\n",
      "Epoch: 18\n",
      "Loss: 0.0011\n",
      "Epoch: 19\n",
      "Loss: 0.0010\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "accuracies, max_accuracy = [], 0\n",
    "for epoch in range(num_epochs):\n",
    "    model_GRU.train()\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    for x, y in train_tensor:\n",
    "        optimizer.zero_grad()\n",
    "        model_GRU.hidden = torch.zeros(1,1,model.hidden_dim)\n",
    "        prediction = model_GRU(x)\n",
    "        #print(prediction.shape)\n",
    "        #print(f'prediction {prediction}')\n",
    "        y_in = y.unsqueeze(1)\n",
    "        #print(f'y_in {y_in}')\n",
    "        # Calculate loss\n",
    "        loss = criterion(prediction, y_in) \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Loss: {:6.4f}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1663581291670,
     "user": {
      "displayName": "Marharyta Varatnitskaya",
      "userId": "06643565085318986478"
     },
     "user_tz": -120
    },
    "id": "1gxVOaMLFBuD",
    "outputId": "16bb538e-f20b-4fe8-ce30-6790c9b9b388"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 5, 5, 2, 2, 2, 1, 7, 5]) tensor([0, 2, 5, 5, 2, 2, 2, 1, 7, 5])\n",
      "tensor([8, 1, 9, 5, 1, 2, 8, 4, 8, 0]) tensor([8, 1, 9, 5, 1, 2, 8, 4, 8, 0])\n",
      "tensor([3, 5, 2, 2, 7, 1, 9, 8, 0, 0]) tensor([3, 5, 2, 2, 7, 1, 9, 8, 0, 0])\n",
      "tensor([8, 2, 2, 3, 0, 7, 3, 9, 0, 1]) tensor([8, 2, 2, 3, 0, 7, 3, 9, 0, 1])\n",
      "tensor([7, 9, 0, 8, 7, 7, 9, 1, 7, 9]) tensor([7, 9, 0, 8, 7, 7, 9, 1, 7, 9])\n",
      "tensor([9, 2, 2, 5, 9, 8, 3, 5, 4, 0]) tensor([9, 2, 2, 5, 9, 8, 3, 5, 4, 0])\n",
      "tensor([7, 5, 2, 8, 0, 7, 8, 2, 8, 8]) tensor([7, 5, 2, 8, 0, 7, 8, 2, 8, 8])\n",
      "tensor([3, 8, 1, 5, 5, 5, 3, 0, 2, 7]) tensor([3, 8, 1, 5, 5, 5, 3, 0, 2, 7])\n",
      "tensor([3, 0, 8, 5, 7, 5, 0, 9, 0, 1]) tensor([3, 0, 8, 5, 7, 5, 0, 9, 0, 1])\n",
      "tensor([2, 7, 8, 2, 9, 0, 5, 2, 1, 7]) tensor([2, 7, 8, 2, 9, 0, 5, 2, 1, 7])\n",
      "tensor([1, 2, 8, 0, 1, 7, 1, 5, 4, 3]) tensor([1, 2, 8, 0, 1, 7, 1, 5, 4, 3])\n",
      "tensor([8, 7, 5, 4, 3, 2, 0, 5, 7, 1]) tensor([8, 7, 5, 4, 3, 2, 0, 5, 7, 1])\n",
      "tensor([2, 2, 0, 0, 9, 5, 3, 2, 2, 5]) tensor([2, 2, 0, 0, 9, 5, 3, 2, 2, 5])\n",
      "tensor([9, 0, 1, 4, 7, 7, 1, 2, 9, 8]) tensor([9, 0, 1, 4, 7, 7, 1, 2, 9, 8])\n",
      "tensor([5, 3, 8, 1, 4, 1, 8, 4, 9, 0]) tensor([5, 3, 8, 1, 4, 1, 8, 4, 9, 0])\n",
      "tensor([8, 0, 3, 2, 9, 5, 3, 4, 2, 1]) tensor([8, 0, 3, 2, 9, 5, 3, 4, 2, 1])\n",
      "tensor([8, 2, 2, 8, 5, 2, 1, 4, 7, 3]) tensor([8, 2, 2, 8, 5, 2, 1, 4, 7, 3])\n",
      "tensor([5, 8, 9, 5, 7, 3, 8, 3, 5, 5]) tensor([5, 8, 9, 5, 7, 3, 8, 3, 5, 5])\n",
      "tensor([8, 5, 7, 0, 4, 1, 2, 4, 5, 4]) tensor([8, 5, 7, 0, 4, 1, 2, 4, 5, 4])\n",
      "tensor([4, 9, 5, 4, 0, 3, 8, 7, 8, 7]) tensor([4, 9, 5, 4, 0, 3, 8, 7, 8, 7])\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "        matches, total = 0, 0\n",
    "        for x, y in test_tensor:\n",
    "            model.eval()\n",
    "            scores = model_GRU(x)\n",
    "            # Compute a softmax over the outputs\n",
    "            predictions = softmax(scores, dim=1)\n",
    "            # Choose the number with the maximum probability\n",
    "            _, batch_out = predictions.max(dim=1)\n",
    "            # Remove fake dimension\n",
    "            batch_out = batch_out.squeeze(1)\n",
    "            # Calculate accuracy\n",
    "            matches += torch.eq(batch_out, y).sum().item()\n",
    "            print(batch_out, y)\n",
    "            total += torch.numel(batch_out)\n",
    "        accuracy = matches / total\n",
    "        print('Accuracy: {:4.2f}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ej9bI3vf12za"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO0HNrL4vX6rwl95islIqYr",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
